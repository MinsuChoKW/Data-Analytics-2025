{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinsuChoKW/Data-Analytics-2025/blob/main/week7_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ_Nk22z1Ln0"
      },
      "source": [
        "# ğŸ“˜ Week 7 - ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§ (Predictive Process Monitoring) (PM4Py)\n",
        "- ì‹¤ìŠµ í•­ëª©: Prefix Encoding, Prediction ë“±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMO7fFFp1Ln1"
      },
      "source": [
        "## í™˜ê²½ ì„¤ì • (Setup)\n",
        "\n",
        "ë³¸ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì•„ë˜ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œë‹¤:\n",
        "\n",
        "* [PM4Py](https://pm4py.fit.fraunhofer.de/)\n",
        "* [pandas](https://pandas.pydata.org/)\n",
        "* [PyTorch](https://pytorch.org/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncGWHMob1Ln1"
      },
      "outputs": [],
      "source": [
        "## Perform the commented out commands to install the dependencies\n",
        "# %pip install pandas\n",
        "# %pip install matplotlib\n",
        "# %pip install pm4py\n",
        "# %pip install torch\n",
        "# %pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuU_NBrD1Ln2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pm4py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.autonotebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wasbDcRt1Ln2"
      },
      "source": [
        "# Predictive Process Mining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ZFXam_Kn1Ln2"
      },
      "source": [
        "## Event Log\n",
        "\n",
        "ë³¸ ì˜ˆì œì—ì„œëŠ” `Sepsis` ë¡œê·¸ë¥¼ í™œìš©í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UZ433IV1Ln2"
      },
      "outputs": [],
      "source": [
        "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
        "\n",
        "sepsis_log = xes_importer.apply('../data/sepsis.xes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zNlGZym1Ln2"
      },
      "outputs": [],
      "source": [
        "len(sepsis_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "sM1MAl4-1Ln2"
      },
      "source": [
        "## Prefix Extraction\n",
        "\n",
        "ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œëŠ” ë‹¤ì–‘í•œ ì˜ˆì¸¡ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” í•œ íŠ¸ë ˆì´ìŠ¤ì˜ ì ‘ë‘(prefix) ë¶€ë¶„ë§Œ ì•Œë ¤ì ¸ ìˆê³ , ê·¸ íŠ¸ë ˆì´ìŠ¤ê°€ ë‚˜íƒ€ë‚´ëŠ” í”„ë¡œì„¸ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì˜ ë¯¸ë˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•´ì•¼ í•œë‹¤ëŠ” ê°€ì •ì„ ë‘”ë‹¤.\n",
        "\n",
        "ì²« ë‹¨ê³„ëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ì— í¬í•¨ëœ íŠ¸ë ˆì´ìŠ¤ë“¤ë¡œë¶€í„° ì ì ˆí•œ prefixë¥¼ ìƒì„±í•˜ì—¬ ì´ë¥¼ í•™ìŠµ ìƒ˜í”Œë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¡œ, ìš°ë¦¬ëŠ” í™˜ìê°€ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— ìµœì¢… ì´ë²¤íŠ¸ë¡œ *Return ER (ì‘ê¸‰ì‹¤ ì¬ë°©ë¬¸)*ì´ ë°œìƒí•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤. ì´ ë•Œ Return ER ì´ë²¤íŠ¸ëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì—, í•´ë‹¹ ì´ë²¤íŠ¸ë¥¼ ì œê±°í•˜ê³  ê·¸ê²ƒì´ ì–´ë–¤ íŠ¸ë ˆì´ìŠ¤ì—ì„œ ë°œìƒí–ˆëŠ”ì§€ë¥¼ ê¸°ì–µí•´ ë‘ì–´ì•¼ í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6SClkwu1Ln3"
      },
      "outputs": [],
      "source": [
        "sepsis_returns = [len(list(filter(lambda e: e[\"concept:name\"] == \"Return ER\" ,trace))) > 0 for trace in sepsis_log]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjyfAVWi1Ln3"
      },
      "outputs": [],
      "source": [
        "# check if this worked\n",
        "print(sepsis_log[3][-1])\n",
        "print(sepsis_returns[3])\n",
        "\n",
        "print(sepsis_log[0][-1])\n",
        "print(sepsis_returns[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp8JaClc1Ln3"
      },
      "source": [
        "ë™ì‹œì—, ìš°ë¦¬ëŠ” í™˜ìê°€ ì‘ê¸‰ì‹¤ì„ ì¬ë°©ë¬¸í•˜ëŠ”ì§€, prefixì˜ ê¸¸ì´ì— ë”°ë¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ì§€ì—ë„ ê´€ì‹¬ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê° íŠ¸ë ˆì´ìŠ¤ì—ì„œ ìµœëŒ€ 10ê°œì˜ ì´ë²¤íŠ¸ê¹Œì§€ë§Œ ë‚¨ê²¨ ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ 10-prefixë¼ê³  í•œë‹¤.\n",
        "\n",
        "**ì£¼ì˜í•  ì ì€, ì—¬ê¸°ì„œ 10ì´ë¼ëŠ” ê°’ì€ ë‹¨ìˆœíˆ ì„ì˜ë¡œ ì •í•œ ê¸¸ì´ì¼ ë¿ì´ë©°, ì¼ë°˜ì ìœ¼ë¡œëŠ” íŠ¹ì • ê¸¸ì´ë§Œì´ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ê¸¸ì´ë‚˜ ëª¨ë“  ê¸¸ì´ì— ëŒ€í•œ ì ‘ë‘ë¥¼ ìƒì„±í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ë˜í•œ, ì¼ë¶€ íŠ¸ë ˆì´ìŠ¤ëŠ” 10ê°œ ë¯¸ë§Œì˜ ì´ë²¤íŠ¸ë¥¼ ê°€ì§€ë¯€ë¡œ ì´ ê²½ìš° ì „ì²´ íŠ¸ë ˆì´ìŠ¤ë¥¼ ì ‘ë‘ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ”ë°, ì´ëŠ” ì‹¤ì œ ì˜ˆì¸¡ ì‘ì—…ì—ì„œëŠ” í¬ê²Œ ìœ ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1DKFH8X1Ln3"
      },
      "outputs": [],
      "source": [
        "# remove Return ER event\n",
        "sepsis_log = pm4py.filter_event_attribute_values(sepsis_log, \"concept:name\", \"Return ER\", level = \"event\", retain=False)\n",
        "\n",
        "from pm4py.objects.log.obj import EventLog, Trace\n",
        "# generate prefixes, note that we need to add the casts to EventLog and Trace to make sure that the result is a PM4Py EventLog object\n",
        "sepsis_prefixes = EventLog([Trace(trace[0:10], attributes = trace.attributes) for trace in sepsis_log])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zygJrGQw1Ln3"
      },
      "outputs": [],
      "source": [
        "# check the trace length\n",
        "print([len(trace) for trace in sepsis_log][0:15])\n",
        "print([len(trace) for trace in sepsis_prefixes][0:15])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFvr7PUM1Ln3"
      },
      "source": [
        "## Prefix Encoding\n",
        "\n",
        "ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•´, íŠ¸ë ˆì´ìŠ¤ë‚˜ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ë²¡í„° í‘œí˜„(vector representation) ìœ¼ë¡œ ë³€í™˜í•´ì•¼í•œë‹¤. ì—¬ê¸°ì„œëŠ” PM4Pyì˜ [feature selection and processing](https://pm4py.fit.fraunhofer.de/documentation#decision-trees) ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ ì„¸ ê°€ì§€ ê¸°ë³¸ì ì¸ ì¸ì½”ë”© ë°©ì‹ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•œë‹¤.\n",
        "\n",
        "ë¬¼ë¡ , ë” ë³µì¡í•œ ì¸ì½”ë”©ë„ ê°€ëŠ¥í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê° íŠ¸ë ˆì´ìŠ¤ë¥¼ í”¼ì²˜ì˜ ì‹œí€€ìŠ¤ë¡œ í‘œí˜„í•˜ì—¬ LSTMê³¼ ê°™ì€ ìˆœì°¨ ëª¨ë¸(sequential models)ì—ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤.\n",
        "\n",
        "### Feature Selection \\& Engineering\n",
        "\n",
        "Prefix encodingì„ ìˆ˜í–‰í•˜ê¸° ì „ì—, ì˜ˆì¸¡ì— ì‚¬ìš©í•  featuresë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤. ë³¸ ì˜ˆì œì—ì„œëŠ” ì´ë²¤íŠ¸ì˜ \"activity\" ì†ì„±ë§Œì„ featureë¡œ ì‚¬ìš©í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì˜ˆì¸¡ ë¬¸ì œì— ë”°ë¼ ì¶”ê°€ì ì¸ íŠ¸ë ˆì´ìŠ¤/ì´ë²¤íŠ¸ ì†ì„±ì„ í¬í•¨ì‹œí‚¬ ìˆ˜ë„ ìˆë‹¤.\n",
        "\n",
        "ì¶”ê°€ì ìœ¼ë¡œ, ìƒˆë¡œìš´ íŠ¸ë ˆì´ìŠ¤ ìˆ˜ì¤€ feature(ì˜ˆ: ìš”ì¼, ì¼€ì´ìŠ¤ ì‹œì‘ ì´í›„ ê²½ê³¼ ì‹œê°„)ì´ë‚˜ ë¡œê·¸ ê¸°ë°˜ feature(ì˜ˆ: ìì›(resource)ì˜ ì›Œí¬ë¡œë“œ, íŠ¹ì • ì‹œì ì—ì„œì˜ í™œì„± ì¼€ì´ìŠ¤ ìˆ˜) ë“±ì„ íŒŒìƒí•˜ì—¬ í™œìš©í•  ìˆ˜ë„ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j4z7U171Ln3"
      },
      "source": [
        "### Encoding as Set of Events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_d6CmfB1Ln3"
      },
      "outputs": [],
      "source": [
        "from pm4py.algo.transformation.log_to_features import algorithm as log_to_features\n",
        "\n",
        "# log_to_feature provides a flexible interface to compute features on an event and trace level\n",
        "data, feature_names = log_to_features.apply(sepsis_prefixes, parameters={\"str_ev_attr\": [\"concept:name\"]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmBtnar51Ln3"
      },
      "source": [
        "`concept:name` ì†ì„±(ì¦‰, ì´ë²¤íŠ¸ ë¼ë²¨)ì˜ í‘œì¤€ì ì¸ ì¸ì½”ë”© ë°©ì‹ì€ *ì›-í•« ì¸ì½”ë”©(one-hot encoding)* ë²¡í„°ì´ë‹¤. ë³¸ ì¸ì½”ë”©ì„ ì‚´í´ë³´ë©´, ê° ìˆ«ìì˜ ì¸ë±ìŠ¤ëŠ” íŠ¹ì§• ë¼ë²¨ ë²¡í„°(feature label vector) ë‚´ì˜ ì¸ë±ìŠ¤ì™€ ì •í™•íˆ ëŒ€ì‘ëœë‹¤.\n",
        "\n",
        "ì¦‰, ì´ë²¤íŠ¸ ë¼ë²¨ ì§‘í•©ì´ ì£¼ì–´ì¡Œì„ ë•Œ, íŠ¹ì • ì´ë²¤íŠ¸ê°€ í•´ë‹¹ ì§‘í•©ì˜ ì–´ëŠ ìœ„ì¹˜ì— ìˆëŠ”ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë²¡í„°ê°€ êµ¬ì„±ë˜ë©°, ê·¸ ìœ„ì¹˜ì—ëŠ” 1ì´, ë‚˜ë¨¸ì§€ ëª¨ë“  ìœ„ì¹˜ì—ëŠ” 0ì´ ë“¤ì–´ê°„ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0I77uRn1Ln3"
      },
      "outputs": [],
      "source": [
        "from pm4py.objects.log.util.log import project_traces\n",
        "def project_nth(log, index):\n",
        "    print(str(project_traces(log)[index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8WMWfSf1Ln4"
      },
      "outputs": [],
      "source": [
        "project_nth(sepsis_prefixes, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7L17G3U1Ln4"
      },
      "outputs": [],
      "source": [
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm9eAb2C1Ln4"
      },
      "outputs": [],
      "source": [
        "print(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifSbr5Sm1Ln4"
      },
      "source": [
        "êµ¬ì„±ëœ ë°ì´í„° í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHCzc-PO1Ln4"
      },
      "outputs": [],
      "source": [
        "np.asarray(data).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqr947ef1Ln4"
      },
      "source": [
        "ì¦‰, PM4PyëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ì— ëŒ€í•œ ì†Œìœ„ *ì§‘í•© ì¶”ìƒí™”(set abstraction)*ì˜ *ì›-í•« ì¸ì½”ë”©(one-hot encoding)*ì„ ì œê³µí•œë‹¤. ì´ëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ ì•ˆì— ì´ 16ê°œì˜ êµ¬ë³„ë˜ëŠ” activityê°€ ìˆìœ¼ë©°, í”¼ì²˜ ë²¡í„°ëŠ” ë‹¨ìˆœíˆ í•´ë‹¹ activityê°€ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ 0ê³¼ 1ë¡œ í‘œí˜„í•œë‹¤ëŠ” ëœ»ì´ë‹¤.\n",
        "\n",
        "ì´ì œ ì´ëŸ¬í•œ í”¼ì²˜ ë²¡í„°ë“¤ì´ ì–´ë–¤ ë¶„í¬(distribution)ë¥¼ ì´ë£¨ëŠ”ì§€ ì‚´í´ë³¸ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5QN-teT1Ln4"
      },
      "outputs": [],
      "source": [
        "# look at the unique vectors and their occurrence frequency/count\n",
        "dist_features = np.unique(data, return_counts= True, axis = 0)\n",
        "print(dist_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGGwb_ZO1Ln4"
      },
      "source": [
        "ì´ ì¤‘ ë¬´ì—‡ì´ ê°€ì¥ í”í•œ feature ë²¡í„°ì¸ê°€?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49OX01jM1Ln4"
      },
      "outputs": [],
      "source": [
        "# argmax give use the index of the most frequent vector\n",
        "dist_features[0][np.argmax(dist_features[1])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOEzLgrX1Ln4"
      },
      "source": [
        "ì‹¤ì œë¡œ ë³¸ í”„ë¡œì„¸ìŠ¤ì—ì„œëŠ” ê±°ì˜ ëª¨ë“  activityê°€ ë°œìƒí•˜ì—¬ ì„ íƒì§€ê°€ ë§ì§€ ì•Šë‹¤. ì¦‰, ì´ ì¸ì½”ë”© ë°©ì‹ì€ ê°€ì¥ ìœ ìš©í•œ ë°©ë²•ì´ë¼ê³  ë³´ê¸°ëŠ” ì–´ë µì§€ë§Œ, ì•„ì£¼ ë‹¨ìˆœí•œ ë°©ì‹ì´ë¼ í•  ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ1L67Ja1Ln4"
      },
      "source": [
        "### Encoding as Bi-Grams / Succession Relation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS7lZhFt1Ln4"
      },
      "outputs": [],
      "source": [
        "data_2gram, feature_names = log_to_features.apply(sepsis_prefixes,\n",
        "                                                  parameters={\"str_ev_attr\": [],\n",
        "                                                        \"str_tr_attr\": [],\n",
        "                                                        \"num_ev_attr\": [],\n",
        "                                                        \"num_tr_attr\": [],\n",
        "                                                        \"str_evsucc_attr\": [\"concept:name\"]})\n",
        "feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpLIAIFm1Ln4"
      },
      "source": [
        "ê° featureëŠ” ì´ë²¤íŠ¸ ë¡œê·¸ì—ì„œ ì„ì˜ì˜ ë‘ activity ì‚¬ì´ì˜ ìˆœì°¨ ê´€ê³„(succession relation, ì¦‰ bigram)ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ íŠ¹ì§•ë“¤ì„ í…ì„œ(tensor) ë¡œ ë³€í™˜í•˜ì—¬ í‘œí˜„í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue8TPK0v1Ln4"
      },
      "outputs": [],
      "source": [
        "data_2gram = np.asarray(data_2gram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmnJDKcJ1Ln5"
      },
      "source": [
        "ë‹¤ì‹œ í•œ ë²ˆ ì²« ë²ˆì§¸ íŠ¸ë ˆì´ìŠ¤ì˜ ì¸ì½”ë”©ì„ ì‚´í´ë³´ì."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYLsfCev1Ln5"
      },
      "outputs": [],
      "source": [
        "project_nth(sepsis_log, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeYY6RsQ1Ln5"
      },
      "outputs": [],
      "source": [
        "print(data_2gram[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmy91mER1Ln5"
      },
      "source": [
        "### Encoding as Bag of Words / Multiset of Events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRxt9vFl1Ln5"
      },
      "source": [
        "ë˜ ë‹¤ë¥¸ ì„ íƒì§€ëŠ” ìì—°ì–´ì²˜ë¦¬(NLP)ì—ì„œ ì‚¬ìš©ë˜ëŠ” [bag-of-words model](https://en.wikipedia.org/wiki/Bag-of-words_model) ëª¨ë¸ë¡œ ì•Œë ¤ì§„ ì¸ì½”ë”© ë°©ì‹ì„ í™œìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ì›-í•« ì¸ì½”ë”©ëœ ì´ë²¤íŠ¸ë“¤ì„ ë©€í‹°ì…‹(multiset) í˜•íƒœë¡œ êµ¬ì„±í•˜ì—¬, ê° activityê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë°œìƒí–ˆëŠ”ì§€ë¥¼ ë¹ˆë„ë¡œ ë°˜ì˜í•˜ëŠ” ë°©ì‹ì´ë‹¤.\n",
        "\n",
        "ì¦‰, ë‹¨ìˆœíˆ í™œë™ì´ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë§Œì„ í‘œí˜„í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê° í™œë™ì˜ ë°œìƒ ë¹ˆë„ê¹Œì§€ íŠ¹ì§• ë²¡í„°ì— ë‹´ê²Œ ëœë‹¤.\n",
        "\n",
        "ì´ ì¸ì½”ë”©ì€ PM4Pyì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µë˜ì§€ëŠ” ì•Šì§€ë§Œ, Pandasì™€ Numpyë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__-KCqIl1Ln5"
      },
      "source": [
        "ê°€ì¥ ë¨¼ì € ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdK0fMy51Ln6"
      },
      "outputs": [],
      "source": [
        "sepsis_df = pm4py.convert_to_dataframe(sepsis_prefixes)\n",
        "sepsis_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FEhjf6l1Ln6"
      },
      "source": [
        "ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•œ ë’¤, ê° ê°œë³„ activityì— í•´ë‹¹í•˜ëŠ” ì´ë²¤íŠ¸ì˜ ë°œìƒ íšŸìˆ˜ë¥¼ ì„¸ì–´ bag-of-words í‘œí˜„ì„ êµ¬ì¶•í•œë‹¤.\n",
        "\n",
        "ì¦‰, íŠ¸ë ˆì´ìŠ¤ ë‹¨ìœ„ë¡œ ì´ë²¤íŠ¸ë¥¼ ë¬¶ì€ í›„, í™œë™ë³„ ë¹ˆë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê° íŠ¸ë ˆì´ìŠ¤ë¥¼ í™œë™ ë°œìƒ ë¹ˆë„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì´ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGbSYdSQ1Ln6"
      },
      "outputs": [],
      "source": [
        "# concept:name refers to the activity\n",
        "# case:concept:name refers to the case identifier\n",
        "sepsis_case_act = sepsis_df.loc[:,[\"case:concept:name\", \"concept:name\"]]\n",
        "sepsis_case_act"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLo0LcTV1Ln6"
      },
      "outputs": [],
      "source": [
        "# Count the occurrence of activities in a trace (no sorting to keep order of traces stable!)\n",
        "sepsis_act_count = sepsis_case_act.groupby([\"case:concept:name\", \"concept:name\"], sort=False).size()\n",
        "sepsis_act_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fWRBnDP1Ln6"
      },
      "source": [
        "ê° íŠ¸ë ˆì´ìŠ¤ë§ˆë‹¤ activityë³„ ë°œìƒ íšŸìˆ˜ë¥¼ ì´ë¯¸ ì§‘ê³„í–ˆìœ¼ë¯€ë¡œ, ì´ì œ ì´ë¥¼ í…ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤. ì¦‰, í–‰ì€ ê°œë³„ ì¼€ì´ìŠ¤ë¥¼, ì—´ì€ ê° activityë¥¼, ê°’ì€ í•´ë‹¹ ì¼€ì´ìŠ¤ì—ì„œ activityê°€ ë°œìƒí•œ íšŸìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë„ë¡ êµ¬ì„±í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Avneo_Mj1Ln6"
      },
      "outputs": [],
      "source": [
        "sepsis_bag = np.asarray(sepsis_act_count.unstack(fill_value=0))\n",
        "sepsis_bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HB3R1yw1Ln6"
      },
      "outputs": [],
      "source": [
        "sepsis_bag.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drwn_f0j1Ln6"
      },
      "source": [
        "ë‹¤ì‹œ í•œ ë²ˆ ì²« ë²ˆì§¸ íŠ¸ë ˆì´ìŠ¤ì˜ ì¸ì½”ë”©ì„ ì‚´í´ë³´ì."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsPtSOoc1Ln6"
      },
      "outputs": [],
      "source": [
        "project_nth(sepsis_log, 0)\n",
        "print(sepsis_bag[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6DvHSZp1Ln6"
      },
      "outputs": [],
      "source": [
        "project_nth(sepsis_log, 1)\n",
        "print(sepsis_bag[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd419vyO1Ln6"
      },
      "source": [
        "ì´ ë°©ì‹ì€ ì´ë¯¸ í›¨ì”¬ ë” í’ë¶€í•œ ì •ë³´ë¥¼ ì œê³µí•´ ì¤€ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jf4H5Qw1Ln6"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "ì´ì œ ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ì ì¸ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³¸ë‹¤. ë³¸ ì˜ˆì œì—ì„œëŠ” ì´ë²¤íŠ¸ `Return ER`ì´ ë°œìƒí–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ì´ì§„ ê²°ê³¼(binary outcome) ë¡œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.\n",
        "\n",
        "**ì£¼ì˜ì‚¬í•­: ì—¬ê¸°ì„œ ê¸°ë³¸ì (basic) ì´ë¼ëŠ” ê²ƒì€ ëª¨ë¸ê³¼ ì¸ì½”ë”© ë°©ì‹ì´ ë†’ì€ í’ˆì§ˆì„ ë³´ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë˜í•œ ì´ë²ˆì— ì„ íƒí•œ ì ‘ë‘(prefix) ì¸ì½”ë”©ë§Œìœ¼ë¡œëŠ” ì‹¤ì œë¡œ ìœ ìš©í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ì˜ ì½”ë“œëŠ” ë‹¨ì§€ ì˜ˆì‹œì™€ ì¶œë°œì ìœ¼ë¡œë§Œ ìƒê°í•˜ì‹œê¸° ë°”ë€ë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPapBTac1Ln6"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga8vif1B1Ln6"
      },
      "source": [
        "#### Target Variable\n",
        "\n",
        "íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ ì‚´í´ë³´ì."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89pR6Fzk1Ln6"
      },
      "outputs": [],
      "source": [
        "np.unique(sepsis_returns, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCoDvqjK1Ln7"
      },
      "outputs": [],
      "source": [
        "# For future processing we need 0 and 1 instead of True and False\n",
        "sepsis_returns = np.asarray(sepsis_returns).astype(int)\n",
        "sepsis_returns.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ascuODK1Ln7"
      },
      "source": [
        "#### Data Scaling & Loading\n",
        "\n",
        "ì´ëŸ¬í•œ ì „ì²˜ë¦¬ ê³¼ì •ì€ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ìì£¼ ë„ì›€ì´ ëœë‹¤.\n",
        "\n",
        "**ì¤‘ìš”**: ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ ì…‹ì„ í¬í•¨í•œ ìƒíƒœì—ì„œ ìŠ¤ì¼€ì¼ë§ì„ ê³„ì‚°í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë°ì´í„° ëˆ„ìˆ˜(data leakage)ê°€ ë°œìƒí•  ìœ„í—˜ì´ ìˆë‹¤. ë‹¤ì‹œ ë§í•´, ë°ì´í„°ì…‹ì˜ ì–´ë–¤ ì†ì„±ì„ í™œìš©í•˜ëŠ” ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì— ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ ì…‹ì„ ë¶„ë¦¬í•´ì•¼ í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U6n3i-Y1Ln7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
        "\n",
        "scaler_x = MinMaxScaler()\n",
        "data_scaled = scaler_x.fit_transform(sepsis_bag)\n",
        "\n",
        "scaler_y = FunctionTransformer() # for binary values scaling does not make sense at all but we keep it for symetry and apply the \"NoOp\" scaler\n",
        "target_scaled = scaler_y.fit_transform(sepsis_returns.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_28VSIh41Ln7"
      },
      "source": [
        "### Model Definition\n",
        "\n",
        "ê°„ë‹¨í•œ ì‹ ê²½ë§ì„ ì •ì˜í•˜ê³  ì˜ë„ì ìœ¼ë¡œ ê³¼ì í•©(overfit) ì„ ì‹œë„í•´ ë³¸ë‹¤. PyTorchë¥¼ ì‚¬ìš©í•´ ê¸°ë³¸ì ì¸ ì‹ ê²½ë§(Neural Network)ì„ êµ¬ì¶•í•œë‹¤.\n",
        "\n",
        "**ì£¼ì˜ì‚¬í•­: ë‹¤ì‹œ í•œ ë²ˆ ê°•ì¡°í•˜ì§€ë§Œ, ì•„ë˜ ë‚´ìš©ì€ ë‹¨ìˆœí•œ ì˜ˆì‹œì¼ ë¿ì´ë©° ëª¨ë¸ ê¶Œì¥ì•ˆì´ ì „í˜€ ì•„ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-DI0wBA1Ln7"
      },
      "outputs": [],
      "source": [
        "class NeuralNetworkBinaryOutcome(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetworkBinaryOutcome, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            torch.nn.Linear(x.shape[1], 64),\n",
        "            nn.BatchNorm1d(num_features=64),\n",
        "            nn.LeakyReLU(),\n",
        "            torch.nn.Linear(64, 128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            torch.nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWLn5ygf1Ln7"
      },
      "source": [
        "PyTorchì—ì„œ ìš°ë¦¬ëŠ” í‘œì¤€ì ì¸ í•™ìŠµ ë£¨í”„(training loop) ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "(í•™ìŠµë£¨í”„: Forward pass - Loss ê³„ì‚° - Backward pass - Optimizer step - Gradient ì´ˆê¸°í™”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haClqeud1Ln7"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model,\n",
        "          loss_fn, measure_fn,\n",
        "          optimizer, device, epochs):\n",
        "\n",
        "    losses = []\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    loop = tqdm(range(epochs))\n",
        "\n",
        "    for epoch in loop:\n",
        "\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            measure = measure_fn(pred, y)\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append([loss.item(), measure.item()])\n",
        "\n",
        "        loop.set_description('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "        loop.set_postfix(loss=loss.item(), measure=measure.item())\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-UlEox_1Ln7"
      },
      "source": [
        "ê·¸ë¦¬ê³  ë‹¤ìŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbb-0un21Ln7"
      },
      "outputs": [],
      "source": [
        "def evaluate_all(dataloader, model, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    result = []\n",
        "    original = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "\n",
        "            result.extend(pred.flatten().numpy())\n",
        "            original.extend(y.flatten().numpy())\n",
        "\n",
        "    return np.asarray(result), np.asarray(original)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qADcaBaV1Ln7"
      },
      "source": [
        "### Training\n",
        "\n",
        "PyTorchì˜ ë°ì´í„° ë¡œë”© ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € ë°ì´í„°ë¥¼ Datasetê³¼ DataLoader í˜•íƒœë¡œ ì¤€ë¹„í•´ì•¼ í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL0vCubU1Ln7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# We need float32 data\n",
        "x = torch.from_numpy(data_scaled.astype('float32'))\n",
        "y = torch.from_numpy(target_scaled.astype('float32'))\n",
        "\n",
        "# Always check the shapes\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "ds = TensorDataset(x, y)\n",
        "train_dataloader = DataLoader(ds, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7fGlCe_1Ln7"
      },
      "source": [
        "ìš°ë¦¬ì˜ data loaderë¡œ ë¶€í„° ì„ì˜ì˜ ìƒ˜í”Œì— ëŒ€í•´ í™•ì¸í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6RxR38t1Ln7"
      },
      "outputs": [],
      "source": [
        "inputs, classes = next(iter(train_dataloader))\n",
        "print(inputs[0])\n",
        "print(classes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFFoS0r1Ln7"
      },
      "source": [
        "ëª¨ë¸ì€ êµì°¨ ì—”íŠ¸ë¡œí”¼(cross entropy) ë¥¼ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•œë‹¤. ê·¸ë¦¬ê³  ì„±ëŠ¥ì„ ë³´ê³ í•  ë•ŒëŠ” í•´ì„í•˜ê¸° ë” ì‰¬ìš´ ì§€í‘œì¸ ì •í™•ë„(accuracy) ë¥¼ ì‚¬ìš©í•œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "vv93vX0W1Ln8"
      },
      "outputs": [],
      "source": [
        "## if you want ot use a GPU you need to tweak the requirements.txt to include the GPU-enabled PyTorch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))\n",
        "\n",
        "# fix a seed to get reproducible results\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = NeuralNetworkBinaryOutcome().to(device)\n",
        "print(model)\n",
        "\n",
        "def get_accuracy(y_prob, y_true):\n",
        "    y_true = y_true.flatten()\n",
        "    y_prob = y_prob.flatten()\n",
        "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
        "    y_prob = y_prob > 0.5\n",
        "    return (y_true == y_prob).sum() / y_true.size(0)\n",
        "measure_fn = get_accuracy\n",
        "\n",
        "results = train(train_dataloader, model,\n",
        "                nn.BCELoss(), # crossentropy for binary target\n",
        "                get_accuracy,\n",
        "                torch.optim.Adam(model.parameters()),\n",
        "                device, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J9c0KBU1Ln8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "results_data = pd.DataFrame(results)\n",
        "results_data.columns = ['loss', 'measure']\n",
        "ax = results_data.plot(subplots=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V8UuzOB1Ln8"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy: \" + str(results[len(results)-1][1]))\n",
        "\n",
        "true_returns = np.unique(sepsis_returns, return_counts=True)[1][0]\n",
        "true_not_returns = np.unique(sepsis_returns, return_counts=True)[1][1]\n",
        "\n",
        "print(\"Accuracy (never returns)\" + str(true_returns / len(sepsis_returns)))\n",
        "print(\"Accuracy (always returns)\" + str(true_not_returns / len(sepsis_returns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjchngzH1Ln8"
      },
      "source": [
        "## Brief Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyVNFYpU1Ln8"
      },
      "source": [
        "ë‹¨ìˆœíˆ í™˜ìëŠ” ì¬ë°©ë¬¸í•˜ì§€ ì•ŠëŠ”ë‹¤ ë¼ê³ ë§Œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ì¡°ê¸ˆ ë‚˜ì•„ì¡Œë‹¤. ê·¸ëŸ¬ë‚˜ í›ˆë ¨ ì…‹ì—ì„œì˜ ì •í™•ë„ì¡°ì°¨ ì—¬ì „íˆ í¬ê²Œ ë³€ë™í•˜ë©°, í•™ìŠµëœ epochì— ë”°ë¥¸ ì†ì‹¤ ê°’ê³¼ ì •í™•ë„ì˜ ë³€ë™ ì¶”ì´ë„ ê·¸ë‹¤ì§€ ì•ˆì •ì ì´ì§€ ì•Šë‹¤. ë”°ë¼ì„œ, ì´ì œëŠ” ê°œë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚´í´ë³´ê³ , ì‹¤ì œ ì •ë‹µ(ground truth)ì— ë”°ë¼ ì˜ˆì¸¡ ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë¶„í¬í•˜ëŠ”ì§€ í™•ì¸í•´ ë³¸ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcZUgrW81Ln8"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(ds, batch_size=256, shuffle=False)\n",
        "result, original = evaluate_all(test_dataloader, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8G7v_pf1Ln8"
      },
      "outputs": [],
      "source": [
        "pd_pos = pd.DataFrame({'Returns': result[original == 1]})\n",
        "pd_neg = pd.DataFrame({'Does not return': result[original == 0]})\n",
        "pd.concat([pd_pos, pd_neg],axis=1).boxplot().set_ylabel('Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBiFDcqb1Ln8"
      },
      "source": [
        "ì¼ì •í•œ ë¶„ë¦¬(separation)ëŠ” ë³´ì´ì§€ë§Œ, ì‹¤ì œë¡œ í™˜ìì˜ ì¬ë°©ë¬¸ì„ ì‹ë³„í•˜ëŠ” ë° ì´ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤ë©´ ê±°ì§“ ì–‘ì„±(false positive) ì´ ë§ì´ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ ë³´ì¸ë‹¤.\n",
        "\n",
        "**ì´ì œëŠ” ë¶„ë¥˜(classification) ê³¼ì œì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë“¤ì„ ê³„ì‚°í•´ì•¼ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì¬í˜„ìœ¨(Recall), ì •ë°€ë„(Precision), í˜¼ë™ í–‰ë ¬(Confusion Matrix), ROC ê³¡ì„ ê³¼ AUC (Area Under the Curve) ë“±ì„ í¬í•¨í•œ ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì˜ˆì¸¡ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqVMQ1S1Ln8"
      },
      "source": [
        "ì´ì™€ ê´€ë ¨í•˜ì—¬ ë°ì´í„° ë¶„í¬ë¥¼ ì‚´í´ë³´ì."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO8-ogMT1Ln8"
      },
      "outputs": [],
      "source": [
        "# count the unique vectors\n",
        "dist_bags = np.unique(sepsis_bag, return_counts=True, axis=0)\n",
        "\n",
        "# sort them with numpy\n",
        "unique_vectors = dist_bags[0][np.argsort(-dist_bags[1])]\n",
        "count_vectors = dist_bags[1][np.argsort(-dist_bags[1])]\n",
        "\n",
        "pd.DataFrame({'Occurrence of unique sample vectors': count_vectors}).boxplot().set_ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPWJH3Bz1Ln8"
      },
      "source": [
        "ë§ì€ íŠ¸ë ˆì´ìŠ¤ê°€ ì™„ì „íˆ ë™ì¼í•œ ìƒ˜í”Œë¡œ ê·€ê²°ëœë‹¤. ì´ì œ 175ê°œ ì´ìƒì˜ íŠ¸ë ˆì´ìŠ¤ë¥¼ ëŒ€í‘œí•˜ëŠ” ê°€ì¥ í”í•œ ìƒ˜í”Œì— ëŒ€í•´, ê·¸ ìƒ˜í”Œì˜ â€œì¬ë°©ë¬¸ ìƒíƒœ(return status)â€ ê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸í•´ ë³¸ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_wP9Jcm1Ln8"
      },
      "outputs": [],
      "source": [
        "# most frequently used vector\n",
        "unique_vectors[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbYhBFr11Ln8"
      },
      "outputs": [],
      "source": [
        "# find the sample indicies for this vector\n",
        "sample_indicies = np.where((sepsis_bag == unique_vectors[0]).all(axis=1))\n",
        "sample_durations = target_scaled[sample_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgZXAYhU1Ln8"
      },
      "outputs": [],
      "source": [
        "np.unique(sample_durations, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izcJPa341Ln9"
      },
      "source": [
        "ë¶„ëª…íˆ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒì€ ì¶”ê°€ì ì¸ ì •ë³´ê°€ ì—†ë‹¤ë©´ ë™ì¼í•œ feature ê°’ì— ëŒ€í•´ì„œëŠ” ì˜ˆì¸¡ ëª¨ë¸ì´ êµ¬ë¶„ì„ í•™ìŠµí•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì´ë‹¤. ë” ë§ì€ ì˜ˆì‹œë¥¼ ì‚´í´ë³¼ ìˆ˜ëŠ” ìˆê² ì§€ë§Œ, Sepsis ì´ë²¤íŠ¸ ë¡œê·¸ì—ì„œ bag-of-words / ì´ë²¤íŠ¸ ë©€í‹°ì…‹ ê¸°ë°˜ ëª¨ë¸ë§Œìœ¼ë¡œëŠ” í™˜ìê°€ ì¬ë°©ë¬¸í• ì§€ ì—¬ë¶€ë¥¼ ì‹ ë¢°ì„± ìˆê²Œ ì˜ˆì¸¡í•˜ê¸° ì–´ë µë‹¤ëŠ” ê²°ë¡ ì— ì´ë¥¸ë‹¤.\n",
        "\n",
        "ì´ë²ˆ ì˜ˆì‹œëŠ” ë‹¨ì§€ ì´ë²¤íŠ¸ ë¡œê·¸ì— í¬í•¨ëœ ì´ë²¤íŠ¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ, í”„ë¡œì„¸ìŠ¤ì˜ ì´ì§„ íŠ¹ì„±(binary process characteristic) ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì˜ˆì¸¡ ëª¨ë¸ì„ ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì˜ˆì‹œì¼ ë¿ì´ë‹¤."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "986d19a5f30747571c3041dc5ec04d8eebcc8ad808bb611da7ac1a06db10f3a6"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}